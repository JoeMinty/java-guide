## 避免活跃性危险
### 死锁
#### 锁顺序死锁
如果所有线程以固定的顺序来获得锁，那么在程序中就不会出现锁顺序死锁的问题。

```
A --> 锁住left  --> 锁住right --> 永久等待
B --> 锁住right --> 锁住left  --> 永久等待
```

#### 动态的锁顺序死锁
```java
  public void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount) throws InsufficientFundsException {
    synchronized (fromAccount) {
      synchronized (toAccount) {
        if (fromAccount.getBalance().compareTo(amount) < 0) {
          throw new InsufficientFundsException();
        } else {
          fromAccount.debit(amount);
          toAccount.debit(amount);
        }
      }  
    }
  }
```
出现死锁的情况
```
A : transferMoney(a, b, 10);
B : transferMoney(b, a, 20);
```

#### 在协作对象之间发生的死锁
如果在持有锁时调用某个外部方法，那么将出现锁活跃性问题。在这个外部方法中可能会获取其他锁（这可能会产生死锁），或者阻塞时间过长，导致其他线程无法及时获得当前被持有的锁

#### 开放调用
如果在调用某个方法时不需要持有锁，那么这种调用被称为开放调用（Open Call）

#### 资源死锁
资源池通常采用信号量来实现，当资源池为空时阻塞。

线程饥饿死锁也是资源死锁的一种。一个任务提交另一个任务，并等待被提交任务在单线程的`Executor`中执行完成。

### 死锁的避免与诊断
在使用细粒度锁的程序中，可以通过使用一种两阶段策略（Two-Part Strategy）来检查代码中的死锁：首先，找出在什么地方将获取多个锁（使这个集合尽量小），然后对所有这些实例进行全局分析，从而确保他们在整个

#### 支持定时的锁
检测死锁和从死锁中恢复过来，显示的使用`Lock`类中的定时`tryLock`功能来代替内置锁机制。

#### 通过线程转储信息来分析死锁
线程转储（Thread Dump）包括各个运行中的线程的栈追踪信息，还包含了加锁信息。

### 其他活跃性危险
#### 饥饿（Starvation）
引起饥饿的最常见资源就是CPU时钟周期。

要避免使用线程优先级，因为这会增加平台依赖性，并可能导致活跃性问题。在大多数并发应用程序中，都可以使用默认的线程优先级。

#### 活锁（Livelock）
活锁通常发生在处理事务消息的应用程序中：如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头。

### 性能与可伸缩性
多线程与单线程相比，总会引入一些额外的性能开销。造成这些开销的操作包含：

- 线程之间的协调（例如加锁，触发信号以及内存同步等）
- 增加的上下文切换
- 线程的创建和销毁
- 线程的调度

要想通过并发来获得更好的性能，需要努力做好两件事情：更有效地利用现有处理资源，以及在出现新的处理资源时使程序尽可能的利用这些新资源。从性能监视的视角来看，CPU需要尽可能的保持忙碌。


#### 性能与可伸缩性
应用程序的性能可以采用多个指标来衡量，例如服务时间、延迟时间、吞吐率、侠侣、可伸缩性以及容量等。

可伸缩性指的是：当增加计算资源时（例如CPU，内存，存储容量或I/O带宽），程序的吞吐量或者处理能力能相应的增加

### 线程引入的开销
#### 上下文切换
线程调度过程中需要访问由操作系统和JVM共享的数据结构。当一个新的线程被切换进来时，它所需要的数据可能不在当前处理器的本地缓存中，因此上下文切换将导致一些缓存缺失，因而线程在首次调度运行时会更加缓慢。这就是为什么调度器会为每个可运行的线程分配一个最小执行时间，即使有许多去其他的线程正在等待执行：它将上下文切换的开销分摊到更多不会中断的执行时间上，从而提高整体的吞吐量

#### 内存同步
内存栅栏（Memory Barrier），可以刷新缓存，使缓存无效。刷新硬件的写缓冲，以及停止执行管道。

JVM会通过优化去掉一些不会发生竞争的锁，从而减少不必要的同步开销。

JVM通过**逸出分析（Escape Analysis）**来找出不会发布到堆的本地对象引用

即使不进行逸出分析，编译器也可以执行锁粒度粗化（Lock Coarsening）操作，即将邻近的同步代码块用同一个锁合并起来。

某个线程中的同步可能会影响其他线程的性能。同步会增加共享内存总线上的通信量，总线的带宽是有限的，并且所有的处理器都将共享这条总线。

#### 阻塞
当在锁上发生竞争时，竞争失败的线程肯定会阻塞。JVM在实现阻塞行为时，可以采用自旋等待（Spin-Waiting，指通过循环不断的尝试获取锁，直到成功）或者通过操作系统挂起被阻塞的线程

等待时间短适合采用自旋等待方式，时间长则适用线程挂起

当线程无法获取某个锁或者由于在某个条件等待获在I/O操作上阻塞时，需要被挂起，在这个过程中将包含两次额外的上下文切换，以及所有必要的操作系统操作和缓存操作：被阻塞的线程在其执行时间片还未用完之前就被交换出去，而在随后当要获取的锁或者其他资源可用时，又再次被切换回来。（由于锁竞争而导致阻塞时，线程在持有锁时将存在一定的开销：当它释放锁时，必须告诉操作系统恢复运行阻塞的线程）

### 减少锁的竞争
串行操作会降低可伸缩性，并且上下文切换也会降低性能，在锁上发生竞争时将同时导致这两种问题，因此减少锁的竞争能够提高性能和可伸缩性

在并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁

有3种方式可以降低锁的竞争程度：
- 减少锁的持有时间
- 降低锁的请求频率
- 使用带有协调机制的独占锁，这些机制允许更高的并发性

#### 缩小锁的范围（“快进快出”）
尽可能缩短锁的持有时间，例如将一些与锁无关的代码移出同步代码块，IO操作

#### 减小锁的粒度
降低线程请求锁的频率，可以通过锁分解和锁分段等技术来实现，采用多个互相独立的锁来保护独立的状态变量，从而改变这些变量在之前由单个锁来保护的情况。
